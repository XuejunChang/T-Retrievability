{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-11T11:18:30.634009Z",
     "start_time": "2025-04-11T11:18:29.690147Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "data_dir = '/nfs/datasets/cxj/retrievability-bias/data/queries'\n",
    "sampled_df = pd.read_csv(f'{data_dir}/random_sampled_docs_100k_from_msmarco.csv', index_col=0).reset_index()\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyterrier_doc2query import Doc2Query, QueryScorer, QueryFilter\n",
    "from pyterrier_dr import ElectraScorer\n",
    "# doc2query = Doc2Query(append=False, num_samples=5)\n",
    "# scorer = ElectraScorer()\n",
    "# pipeline = doc2query >> QueryScorer(scorer) >> QueryFilter(t=3.21484375)\n",
    "# pipeline(sampled_df[:2])"
   ],
   "id": "5da64e8b75b99e25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = sampled_df[:2]",
   "id": "6bced30bbc9f8d45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "93db19fd42e77e9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:15:42.655281Z",
     "start_time": "2025-04-14T17:15:40.728243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline(\"text2text-generation\", model=\"macavaney/doc2query-t5-base-msmarco\")"
   ],
   "id": "954aaff3e5704752",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:18:36.729616Z",
     "start_time": "2025-04-14T17:18:36.727088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_queries(text, num_queries=3):\n",
    "    prompt = f\"generate queries: {text}\"\n",
    "    return [q['generated_text'] for q in generator(prompt, num_return_sequences=num_queries, max_length=64, do_sample=True,\n",
    "          top_k=50,)]"
   ],
   "id": "9941944c5c3ffd60",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:29:48.893450Z",
     "start_time": "2025-04-14T17:29:48.578513Z"
    }
   },
   "cell_type": "code",
   "source": "df['generated_queries'] = df['text'].apply(lambda x: generate_queries(x, num_queries=3))\n",
   "id": "64456d63819f8d8e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:30:24.059675Z",
     "start_time": "2025-04-14T17:30:16.042624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "scorer = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def score_queries(doc, queries):\n",
    "    pairs = [(query, doc) for query in queries]\n",
    "    scores = scorer.predict(pairs)\n",
    "    return scores"
   ],
   "id": "5787bfeeb6f1d2b4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:30:24.972796Z",
     "start_time": "2025-04-14T17:30:24.937245Z"
    }
   },
   "cell_type": "code",
   "source": "df['query_scores'] = df.apply(lambda row: score_queries(row['text'], row['generated_queries']), axis=1)",
   "id": "8275e8e35d8af2c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:30:28.348682Z",
     "start_time": "2025-04-14T17:30:28.346533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def select_top_query(queries, scores):\n",
    "    best_idx = scores.index(max(scores))\n",
    "    return queries[best_idx]"
   ],
   "id": "2635bdc2fa59bfc9",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:30:30.822523Z",
     "start_time": "2025-04-14T17:30:30.819755Z"
    }
   },
   "cell_type": "code",
   "source": "df['selected_query'] = df.apply(lambda row: select_top_query(row['generated_queries'], list(row['query_scores'])), axis=1)",
   "id": "587127e2535ee5bc",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:30:32.983462Z",
     "start_time": "2025-04-14T17:30:32.978421Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "4523bce4a0e2fdab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  doc_id                         text  \\\n",
       "0     d1  This is the first document.   \n",
       "1     d2   Second document goes here.   \n",
       "\n",
       "                                   generated_queries  \\\n",
       "0  [how to generate queries, excel generate a que...   \n",
       "1  [in which document to use instead of generate ...   \n",
       "\n",
       "                                    query_scores  \\\n",
       "0  [1.2218982e-05, 5.7999936e-05, 0.00028478578]   \n",
       "1   [0.0013623098, 1.3263578e-05, 1.6412321e-05]   \n",
       "\n",
       "                                      selected_query  \n",
       "0                   which query generates a document  \n",
       "1  in which document to use instead of generate q...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated_queries</th>\n",
       "      <th>query_scores</th>\n",
       "      <th>selected_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>This is the first document.</td>\n",
       "      <td>[how to generate queries, excel generate a que...</td>\n",
       "      <td>[1.2218982e-05, 5.7999936e-05, 0.00028478578]</td>\n",
       "      <td>which query generates a document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>Second document goes here.</td>\n",
       "      <td>[in which document to use instead of generate ...</td>\n",
       "      <td>[0.0013623098, 1.3263578e-05, 1.6412321e-05]</td>\n",
       "      <td>in which document to use instead of generate q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.10.15]",
   "language": "python",
   "name": "conda-env-py3.10.15-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
