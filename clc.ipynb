{
 "cells": [
  {
   "cell_type": "code",
   "id": "d5014e0f-9e01-4300-83c3-c0bf16126f98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T22:35:13.695461Z",
     "start_time": "2025-03-10T22:35:13.616468Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.java.started():\n",
    "    pt.java.init()\n",
    "\n",
    "pt.tqdm.pandas()\n",
    "import ir_datasets\n",
    "import ir_measures\n",
    "from ir_measures import * # imports all supported measures, e.g., AP, nDCG, RR, P\n",
    "import statistics\n",
    "\n",
    "import os\n",
    "os.environ[\"PIP_ROOT_USER_ACTION\"] = \"ignore\"\n",
    "import glob\n",
    "from itertools import islice\n",
    "\n",
    "# dataset_name = 'msmarco-passage'\n",
    "# dataset = pt.get_dataset(f'irds:{dataset_name}')\n",
    "\n",
    "dataset = pt.get_dataset(f'irds:msmarco-passage')\n",
    "# df_dataset = pd.DataFrame(dataset.get_corpus_iter(verbose=True))\n",
    "eval_dev = pt.get_dataset(f'irds:msmarco-passage/dev')\n",
    "dev_topics = eval_dev.get_topics()\n",
    "# qrels = eval_dev.get_qrels()\n",
    "\n",
    "dev_eval = ir_datasets.load(\"msmarco-passage/dev\")\n",
    "# topics = pd.DataFrame(eval.queries_iter())\n",
    "dev_qrels = pd.DataFrame(dev_eval.qrels_iter())\n",
    "\n",
    "\n",
    "\n",
    "dl19 = pt.get_dataset('irds:msmarco-passage/trec-dl-2019')\n",
    "dl19_topics = dl19.get_topics()\n",
    "# dl19_qrels = dl19.get_qrels()\n",
    "\n",
    "dl20 = pt.get_dataset('irds:msmarco-passage/trec-dl-2020')\n",
    "dl20_topics = dl20.get_topics()\n",
    "# dl20_qrels = dl20.get_qrels()\n",
    "\n",
    "dl19_eval = ir_datasets.load(\"msmarco-passage/trec-dl-2019\")\n",
    "# topics = pd.DataFrame(eval.queries_iter())\n",
    "dl19_qrels = pd.DataFrame(dl19_eval.qrels_iter())\n",
    "\n",
    "\n",
    "dl20_eval = ir_datasets.load(\"msmarco-passage/trec-dl-2020\")\n",
    "# topics = pd.DataFrame(eval.queries_iter())\n",
    "dl20_qrels = pd.DataFrame(dl20_eval.qrels_iter())\n",
    "\n",
    "dl1920_topics = pd.concat([dl19_topics, dl20_topics], ignore_index=True)\n",
    "dl1920_qrels = pd.concat([dl19_qrels, dl20_qrels], ignore_index=True)\n",
    "\n",
    "\n",
    "# def Gini(x):\n",
    "#     # Ensure the array is sorted\n",
    "#     sorted_x = np.sort(x)\n",
    "#     n = len(x)\n",
    "#     # Calculate the Lorenz curve cumulative values\n",
    "#     cumulative_x = np.cumsum(sorted_x, dtype=float)\n",
    "#     # Calculate the Gini coefficient using the Lorenz curve\n",
    "#     gini = (n + 1 - 2 * np.sum(cumulative_x) / cumulative_x[-1]) / n\n",
    "#     print(f'gini: {gini}')\n",
    "#     return gini\n",
    "\n",
    "# def Gini(arr):\n",
    "#     arr = np.abs(arr)\n",
    "#     sum_i = 0.0\n",
    "#     for x_i in arr:\n",
    "#         sum_j = 0.0\n",
    "#         for x_j in arr:\n",
    "#             sum_j = sum_j + np.abs(x_i-x_j)\n",
    "#         sum_i = sum_i + sum_j\n",
    "#     denom = 2 * len(arr) + np.sum(arr)\n",
    "#     return sum_i/denom\n",
    "\n",
    "def Gini(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    sorted_arr = np.sort(arr)\n",
    "    cumarr = np.cumsum(sorted_arr)\n",
    "    sumarr = cumarr[-1]\n",
    "    n = len(arr)\n",
    "    gini = (n + 1 - 2 * np.sum(cumarr) / sumarr) / n\n",
    "    return gini\n",
    "\n",
    "\n",
    "\n",
    "def calc_eff(df,qrels):\n",
    "    df['query_id'] = df['qid'].astype(str)\n",
    "    df['doc_id'] = df['docno'].astype(str)\n",
    "    m = ir_measures.calc_aggregate([nDCG @ 10, RR], qrels, df)\n",
    "\n",
    "    return m[nDCG @ 10], m[RR]\n",
    "\n",
    "def calc_r_gini_stats(df, topics, scoredF, filter=False):\n",
    "    if not os.path.exists(scoredF):\n",
    "        if filter:\n",
    "            print('filtering')\n",
    "            qids_to_keep = topics['qid'].to_list()\n",
    "            mask = np.logical_or.reduce([df[\"qid\"] == val for val in qids_to_keep])\n",
    "            df = df[mask]\n",
    "\n",
    "        print('groupby docno ...')\n",
    "        grouped = df.groupby(\"docno\")[['r_score']].sum().reset_index()\n",
    "\n",
    "        print(f'save to {scoredF}')\n",
    "        grouped.to_csv(scoredF, index=False)\n",
    "    else:\n",
    "        grouped = pd.read_csv(scoredF, index_col=0).reset_index()\n",
    "        print(f'loaded from {scoredF}')\n",
    "\n",
    "    print('calc mean, std_dev')\n",
    "    scores = grouped['r_score'].to_list()\n",
    "    mean = statistics.mean(scores)\n",
    "    std_dev = statistics.stdev(scores)\n",
    "    print('calc gini')\n",
    "    gini_value = Gini(scores)\n",
    "\n",
    "    avg_r_score = grouped['r_score'].mean()\n",
    "    min_r_score = grouped['r_score'].min()\n",
    "    max_r_score = grouped['r_score'].max()\n",
    "\n",
    "    return mean, std_dev, gini_value, avg_r_score, min_r_score, max_r_score\n",
    "\n",
    "data_dir = f'/nfs/datasets/cxj/retrievability-bias-from_resources_ok'\n",
    "# root_dir = '/root/retrievability-bias'\n",
    "prg_dir = '/nfs/primary/retrievability-bias/results/expt1'\n",
    "# os.makedirs(f'{root_dir}/allresults', exist_ok=True)\n",
    "os.makedirs(f'{data_dir}/allresults', exist_ok=True)\n",
    "os.makedirs(prg_dir, exist_ok=True)\n",
    "\n",
    "def group_exec(run_model, thres, grps,eval_topics, grouped, qrels, filter=False):\n",
    "    # for modelname in ['bm25', 'bm25_monot5', 'rtr_splade', 'tctcolbert','bm25_tctcolbert']:\n",
    "    # for modelname in ['bm25', 'bm25_monot5', 'splade', 'tctcolbert','bm25_tctcolbert']:\n",
    "    for modelname in run_model:\n",
    "        # os.makedirs(f'{root_dir}/{modelname}/groups/new_clustered/', exist_ok=True)\n",
    "        os.makedirs(f'{data_dir}/{modelname}/groups/new_clustered/', exist_ok=True)\n",
    "        this_model_res = []\n",
    "        for threshold in thres:\n",
    "            \"\"\"\n",
    "            Calc retrievability score for each doc\n",
    "            \"\"\"\n",
    "            print(f'start  {modelname} --> {eval_topics} --number of groups {grps} --> threshold {threshold}')\n",
    "            # origin_topics = eval_topics.split('_')[0]\n",
    "            origin_topics = 'dev'\n",
    "            rscore_csv = f'{data_dir}/{modelname}/df_{modelname}_{origin_topics}_rscore_{threshold}.csv'\n",
    "            if os.path.exists(rscore_csv):\n",
    "                print(f'loading {rscore_csv}')\n",
    "                df = pd.read_csv(rscore_csv, index_col=0).reset_index()\n",
    "            else:\n",
    "                csv = f'{data_dir}/{modelname}/df_{modelname}_{origin_topics}_{threshold}.csv'\n",
    "                df = pd.read_csv(csv, index_col=0).reset_index()\n",
    "                df['r_score'] = df['rank'].progress_apply(lambda x: 100 / np.log(x + 2))\n",
    "                print(f'saving {rscore_csv}')\n",
    "                df.to_csv(rscore_csv, index=False)\n",
    "                print(f'done')\n",
    "\n",
    "            \"\"\"\n",
    "            each group computation\n",
    "            \"\"\"\n",
    "            res = []\n",
    "            for group_id, queries_df in grouped:\n",
    "                print(f'Each group computation: {modelname} ----> {eval_topics} --> number of groups {grps} ---> group_id={group_id} ----> threshold {threshold}')\n",
    "                scoredF = f'{data_dir}/{modelname}/groups/{modelname}_{eval_topics}_{grps}_G{group_id}_T{threshold}.csv' # each group computation\n",
    "                mean, std_dev, gini_value, avg_r_score, min_r_score, max_r_score = calc_r_gini_stats(df, queries_df, scoredF, filter=filter)\n",
    "                nDCG10, rr = calc_eff(df, qrels) if not filter else (None, None)\n",
    "                group_res = [modelname, threshold, grps, group_id, mean, std_dev, gini_value, avg_r_score, min_r_score, max_r_score, nDCG10, rr]\n",
    "                res.append(group_res)\n",
    "\n",
    "            \"\"\"\n",
    "            Form a csv file\n",
    "            \"\"\"\n",
    "            print(f'merge into a dataframe for {modelname} ----> {eval_topics} ---> nubmer of groups:{grps} ----> threshold {threshold}')\n",
    "            df_threshold = pd.DataFrame(res, columns=['modelname', 'threshold','grps', 'group_id', 'mean', 'std', 'gini', 'avg_r_score', 'min_r_score', 'max_r_score', 'nDCG@10', 'RR'])\n",
    "            res_csv = f'{data_dir}/{modelname}/groups/new_clustered/result_{modelname}_{eval_topics}_{grps}_T{threshold}_avg_rscore_new_gini.csv'\n",
    "            if os.path.exists(res_csv):\n",
    "                os.remove(res_csv)\n",
    "                print(f'old {res_csv} removed')\n",
    "        \n",
    "            print(f'saving {res_csv}')\n",
    "            df_threshold.to_csv(res_csv, index=False)\n",
    "            print('done')\n",
    "\n",
    "            \"\"\"\n",
    "            Computation over groups\n",
    "            \"\"\"\n",
    "            print(f'Computation over groups {modelname} --> {eval_topics} --> nubmer of groups:{grps} --> threshold {threshold}')\n",
    "            ginis = df_threshold['gini']\n",
    "            min_gini, mean_gini, max_gini = ginis.min(), ginis.mean(), ginis.max()\n",
    "            avg_localiszed_gini = Gini(df_threshold['avg_r_score'].to_list())\n",
    "            min_localiszed_gini = Gini(df_threshold['min_r_score'].to_list())\n",
    "            max_localiszed_gini = Gini(df_threshold['max_r_score'].to_list())\n",
    "            nDCG10 = df_threshold['nDCG@10'].mean()\n",
    "            rr = df_threshold['RR'].mean()\n",
    "            this_model_res.append([modelname, threshold, grps, min_gini, mean_gini, max_gini, avg_localiszed_gini, min_localiszed_gini, max_localiszed_gini, nDCG10, rr])\n",
    "\n",
    "        \"\"\"\n",
    "        Form a file with all thresholds.\n",
    "        \"\"\"\n",
    "        print(f'Form a file with all thresholds: {modelname} --> {eval_topics} --> nubmer of groups:{grps}')\n",
    "        res_df = pd.DataFrame(this_model_res,\n",
    "                              columns=['modelname', 'threshold', 'grps', 'min_gini', 'mean_gini', 'max_gini', 'avg_localiszed_gini', 'min_localiszed_gini', 'max_localiszed_gini', 'nDCG@10', 'RR'])\n",
    "        res_df = res_df.round(4)\n",
    "        res_df = res_df.sort_values(by='grps')\n",
    "\n",
    "        res_csv = f'{data_dir}/allresults/result_{modelname}_{eval_topics}_{grps}_stats_avg_rscore_new_gini.csv'\n",
    "        if os.path.exists(res_csv):\n",
    "            os.remove(res_csv)\n",
    "            print(f'old {res_csv} removed')\n",
    "                        \n",
    "        print(f'saving {res_csv}')\n",
    "        res_df.to_csv(res_csv, index=False)\n",
    "        os.system(f'cp -r {res_csv} {prg_dir}/')\n",
    "        print(f'copied into {prg_dir}/')\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "# cluster = int(sys.argv[1])\n",
    "run_model = sys.argv[1:]\n",
    "def cal_groups():\n",
    "    # dev_topics['cluster'] = 0\n",
    "    # grouped = dev_topics.groupby('cluster')\n",
    "    # group_exec([0],run_model, 1,'dev_all', grouped, dev_qrels, filter=False)\n",
    "\n",
    "    # dl1920_topics['cluster'] = 0\n",
    "    # dl1920_all = dl1920_topics.groupby('cluster')\n",
    "    # group_exec(nc,'dl1920_all', dl1920_all, dl1920_qrels, filter=False)\n",
    "\n",
    "    num_clusters = [500, 1000, 2000, 5000, 10000]\n",
    "    for nc in num_clusters:\n",
    "        print(f'For {nc} groups')\n",
    "        csv = f'{prg_dir}/clustered_dev_queries_by_{nc}.csv'\n",
    "        topics_sampled = pd.read_csv(csv, index_col=0).reset_index()\n",
    "        grouped = topics_sampled.groupby('cluster')\n",
    "        thres = [0, 30, 60, 90]\n",
    "        group_exec(run_model, thres, nc, 'dev_topics_grps', grouped, dev_qrels, filter=True)\n",
    "\n",
    "def convert_dev_all():\n",
    "    res_df = pd.DataFrame()\n",
    "    eval_topics = 'dev_all'\n",
    "    group_nums = [1]\n",
    "    for modelname in ['bm25', 'bm25_monot5', 'splade', 'tctcolbert', 'bm25_tctcolbert']:\n",
    "        for grps in group_nums:\n",
    "            csv = f'{data_dir}/allresults/result_{modelname}_{eval_topics}_{grps}_stats_avg_rscore_new_gini.csv'\n",
    "            print(f'loading {csv}')\n",
    "            df = pd.read_csv(csv, index_col=0).reset_index()\n",
    "            res_df = pd.concat([res_df, df], ignore_index=True)\n",
    "\n",
    "    csv = f'{data_dir}/allresults/result_all_models_all_groups_avg_rscore_new_gini.csv'\n",
    "    res_df.to_csv(csv, index=False)\n",
    "    os.system(f'cp -r {csv} {prg_dir}/')\n",
    "    print(f'copied into {prg_dir}/')\n",
    "\n",
    "def convert2dec4():\n",
    "    res_df = pd.DataFrame()\n",
    "    eval_topics = 'dev_topics_grps'\n",
    "    group_nums = [500, 1000, 2000, 5000, 10000]\n",
    "    for modelname in ['bm25', 'bm25_monot5', 'splade', 'tctcolbert', 'bm25_tctcolbert']:\n",
    "        for grps in group_nums:\n",
    "            csv = f'{data_dir}/allresults/result_{modelname}_{eval_topics}_{grps}_stats_avg_rscore_new_gini.csv'\n",
    "            print(f'loading {csv}')\n",
    "            df = pd.read_csv(csv, index_col=0).reset_index()\n",
    "            res_df = pd.concat([res_df, df], ignore_index=True)\n",
    "\n",
    "    csv = f'{data_dir}/allresults/result_all_models_all_groups_avg_rscore_new_gini.csv'\n",
    "    res_df.to_csv(csv, index=False)\n",
    "    os.system(f'cp -r {csv} {prg_dir}/')\n",
    "    print(f'copied into {prg_dir}/')\n",
    "\n",
    "# cal_groups()\n",
    "convert2dec4()\n",
    "# convert_dev_all()"
   ],
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Unable to find javac",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/jnius/env.py:347\u001B[0m, in \u001B[0;36mget_jdk_home\u001B[0;34m(platform)\u001B[0m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 347\u001B[0m     jdk_home \u001B[38;5;241m=\u001B[39m \u001B[43mrealpath\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwhich\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mjavac\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbin/javac\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/posixpath.py:395\u001B[0m, in \u001B[0;36mrealpath\u001B[0;34m(filename, strict)\u001B[0m\n\u001B[1;32m    393\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the canonical path of the specified filename, eliminating any\u001B[39;00m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;124;03msymbolic links encountered in the path.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 395\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    396\u001B[0m     path, ok \u001B[38;5;241m=\u001B[39m _joinrealpath(filename[:\u001B[38;5;241m0\u001B[39m], filename, strict, {})\n",
      "\u001B[0;31mTypeError\u001B[0m: expected str, bytes or os.PathLike object, not NoneType",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpyterrier\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpt\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m pt\u001B[38;5;241m.\u001B[39mjava\u001B[38;5;241m.\u001B[39mstarted():\n\u001B[0;32m---> 10\u001B[0m     \u001B[43mpt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjava\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m pt\u001B[38;5;241m.\u001B[39mtqdm\u001B[38;5;241m.\u001B[39mpandas()\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mir_datasets\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pyterrier/java/_utils.py:102\u001B[0m, in \u001B[0;36minit\u001B[0;34m()\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21minit\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 102\u001B[0m     \u001B[43m_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pyterrier/utils.py:94\u001B[0m, in \u001B[0;36monce.<locals>._once.<locals>._wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m has already been run\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# how to handle errors?\u001B[39;00m\n\u001B[0;32m---> 94\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m called \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/pyterrier/java/_utils.py:134\u001B[0m, in \u001B[0;36m_init\u001B[0;34m(trigger)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, initializer \u001B[38;5;129;01min\u001B[39;00m initializers:\n\u001B[1;32m    132\u001B[0m     initializer\u001B[38;5;241m.\u001B[39mpre_init(jnius_config)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mjnius\u001B[39;00m \u001B[38;5;66;03m# noqa: PT100 \u001B[39;00m\n\u001B[1;32m    135\u001B[0m _started \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;66;03m# run post-initialization setup\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/jnius/__init__.py:45\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjnius\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mreflect\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# XXX monkey patch methods that cannot be in cython.\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# Cython doesn't allow to set new attribute on methods it compiled\u001B[39;00m\n\u001B[1;32m     50\u001B[0m HASHCODE_MAX \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m31\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/jnius/reflect.py:19\u001B[0m\n\u001B[1;32m     14\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautoclass\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mensureclass\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprotocol_map\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     16\u001B[0m log \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkivy\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mgetChild(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mClass\u001B[39;00m(JavaClass, metaclass\u001B[38;5;241m=\u001B[39mMetaJavaClass):\n\u001B[1;32m     20\u001B[0m     __javaclass__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjava/lang/Class\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     22\u001B[0m     desiredAssertionStatus \u001B[38;5;241m=\u001B[39m JavaMethod(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m()Z\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32mjnius/jnius_export_class.pxi:117\u001B[0m, in \u001B[0;36mjnius.MetaJavaClass.__new__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mjnius/jnius_export_class.pxi:177\u001B[0m, in \u001B[0;36mjnius.MetaJavaClass.resolve_class\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mjnius/jnius_env.pxi:11\u001B[0m, in \u001B[0;36mjnius.get_jnienv\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mjnius/jnius_jvm_dlopen.pxi:95\u001B[0m, in \u001B[0;36mjnius.get_platform_jnienv\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mjnius/jnius_jvm_dlopen.pxi:54\u001B[0m, in \u001B[0;36mjnius.create_jnienv\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/jnius/env.py:60\u001B[0m, in \u001B[0;36mget_java_setup\u001B[0;34m(platform)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# go hunting for Javac and Java programs, in that order\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_set(JAVA_HOME):\n\u001B[0;32m---> 60\u001B[0m     JAVA_HOME \u001B[38;5;241m=\u001B[39m \u001B[43mget_jdk_home\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplatform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_set(JAVA_HOME):\n\u001B[1;32m     63\u001B[0m     JAVA_HOME \u001B[38;5;241m=\u001B[39m get_jre_home(platform)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/jnius/env.py:351\u001B[0m, in \u001B[0;36mget_jdk_home\u001B[0;34m(platform)\u001B[0m\n\u001B[1;32m    347\u001B[0m             jdk_home \u001B[38;5;241m=\u001B[39m realpath(\n\u001B[1;32m    348\u001B[0m                 which(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjavac\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    349\u001B[0m             )\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbin/javac\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    350\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m--> 351\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnable to find javac\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m jdk_home \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exists(jdk_home):\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mException\u001B[0m: Unable to find javac"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T22:35:31.678816Z",
     "start_time": "2025-03-10T22:35:31.677319Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d448a386473dce4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1f4f612e557a43a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
